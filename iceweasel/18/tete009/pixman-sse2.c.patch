diff -r 7f26aac55b28 gfx/cairo/libpixman/src/pixman-sse2.c
--- a/gfx/cairo/libpixman/src/pixman-sse2.c	Sat Jul 14 16:55:18 2012 +0900
+++ b/gfx/cairo/libpixman/src/pixman-sse2.c	Sun Jul 15 20:18:12 2012 +0900
@@ -349,16 +349,23 @@ load_128_unaligned (const __m128i* src)
  */
 static force_inline void
 save_128_write_combining (__m128i* dst,
                           __m128i  data)
 {
     _mm_stream_si128 (dst, data);
 }
 
+/* save 1 pixels using Write Combining memory */
+static force_inline void
+save_32_write_combining (int* dst, int data)
+{
+    _mm_stream_si32 (dst, data);
+}
+
 /* save 4 pixels on a 16-byte boundary aligned address */
 static force_inline void
 save_128_aligned (__m128i* dst,
                   __m128i  data)
 {
     _mm_store_si128 (dst, data);
 }
 
@@ -3227,28 +3234,36 @@ sse2_composite_over_n_8_8888 (pixman_imp
 
 	    w--;
 	    dst++;
 	}
     }
 
 }
 
+#ifdef TT_MEMUTIL
+extern uint32_t dwNonTemporalDataSizeMin;
+extern uint32_t dwNonTemporalMemcpySizeMin;
+#endif
+
 static pixman_bool_t
 pixman_fill_sse2 (uint32_t *bits,
                   int       stride,
                   int       bpp,
                   int       x,
                   int       y,
                   int       width,
                   int       height,
                   uint32_t  data)
 {
     uint32_t byte_width;
     uint8_t         *byte_line;
+#ifdef TT_MEMUTIL
+    pixman_bool_t use_nontemporal_fill;
+#endif
 
     __m128i xmm_def;
 
     if (bpp == 8)
     {
 	uint8_t b;
 	uint16_t w;
 
@@ -3277,16 +3292,20 @@ pixman_fill_sse2 (uint32_t *bits,
 	byte_width = 4 * width;
 	stride *= 4;
     }
     else
     {
 	return FALSE;
     }
 
+#ifdef TT_MEMUTIL
+    use_nontemporal_fill = ((uint32_t)(byte_width * height) > dwNonTemporalDataSizeMin);
+#endif
+
     xmm_def = create_mask_2x32_128 (data, data);
 
     while (height--)
     {
 	int w;
 	uint8_t *d = byte_line;
 	byte_line += stride;
 	w = byte_width;
@@ -3300,16 +3319,81 @@ pixman_fill_sse2 (uint32_t *bits,
 
 	while (w >= 2 && ((unsigned long)d & 3))
 	{
 	    *(uint16_t *)d = data;
 	    w -= 2;
 	    d += 2;
 	}
 
+#ifdef TT_MEMUTIL
+if (use_nontemporal_fill)
+{
+	while (w >= 4 && ((unsigned long)d & 15))
+	{
+	    save_32_write_combining ((int*)d, (int)data);
+
+	    w -= 4;
+	    d += 4;
+	}
+
+	while (w >= 128)
+	{
+	    save_128_write_combining ((__m128i*)(d),     xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 16),  xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 32),  xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 48),  xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 64),  xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 80),  xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 96),  xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 112), xmm_def);
+
+	    d += 128;
+	    w -= 128;
+	}
+
+	if (w >= 64)
+	{
+	    save_128_write_combining ((__m128i*)(d),     xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 16),  xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 32),  xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 48),  xmm_def);
+
+	    d += 64;
+	    w -= 64;
+	}
+
+	if (w >= 32)
+	{
+	    save_128_write_combining ((__m128i*)(d),     xmm_def);
+	    save_128_write_combining ((__m128i*)(d + 16),  xmm_def);
+
+	    d += 32;
+	    w -= 32;
+	}
+
+	if (w >= 16)
+	{
+	    save_128_write_combining ((__m128i*)(d),     xmm_def);
+
+	    d += 16;
+	    w -= 16;
+	}
+
+	while (w >= 4)
+	{
+	    save_32_write_combining ((int*)d, (int)data);
+
+	    w -= 4;
+	    d += 4;
+	}
+}
+else
+#endif
+{
 	while (w >= 4 && ((unsigned long)d & 15))
 	{
 	    *(uint32_t *)d = data;
 
 	    w -= 4;
 	    d += 4;
 	}
 
@@ -3358,32 +3442,40 @@ pixman_fill_sse2 (uint32_t *bits,
 
 	while (w >= 4)
 	{
 	    *(uint32_t *)d = data;
 
 	    w -= 4;
 	    d += 4;
 	}
+}
 
 	if (w >= 2)
 	{
 	    *(uint16_t *)d = data;
 	    w -= 2;
 	    d += 2;
 	}
 
 	if (w >= 1)
 	{
 	    *(uint8_t *)d = data;
 	    w -= 1;
 	    d += 1;
 	}
     }
 
+#ifdef TT_MEMUTIL
+    if (use_nontemporal_fill)
+    {
+        _mm_sfence();
+    }
+#endif
+
     return TRUE;
 }
 
 static void
 sse2_composite_src_n_8_8888 (pixman_implementation_t *imp,
                              pixman_composite_info_t *info)
 {
     PIXMAN_COMPOSITE_ARGS (info);
@@ -4457,16 +4549,19 @@ pixman_blt_sse2 (uint32_t *src_bits,
                  int       dest_x,
                  int       dest_y,
                  int       width,
                  int       height)
 {
     uint8_t *   src_bytes;
     uint8_t *   dst_bytes;
     int byte_width;
+#ifdef TT_MEMUTIL
+    pixman_bool_t use_nontemporal_copy;
+#endif
 
     if (src_bpp != dst_bpp)
 	return FALSE;
 
     if (src_bpp == 16)
     {
 	src_stride = src_stride * (int) sizeof (uint32_t) / 2;
 	dst_stride = dst_stride * (int) sizeof (uint32_t) / 2;
@@ -4486,16 +4581,20 @@ pixman_blt_sse2 (uint32_t *src_bits,
 	src_stride *= 4;
 	dst_stride *= 4;
     }
     else
     {
 	return FALSE;
     }
 
+#ifdef TT_MEMUTIL
+    use_nontemporal_copy = ((uint32_t)(byte_width * height) > dwNonTemporalMemcpySizeMin);
+#endif
+
     while (height--)
     {
 	int w;
 	uint8_t *s = src_bytes;
 	uint8_t *d = dst_bytes;
 	src_bytes += src_stride;
 	dst_bytes += dst_stride;
 	w = byte_width;
@@ -4503,34 +4602,88 @@ pixman_blt_sse2 (uint32_t *src_bits,
 	while (w >= 2 && ((unsigned long)d & 3))
 	{
 	    *(uint16_t *)d = *(uint16_t *)s;
 	    w -= 2;
 	    s += 2;
 	    d += 2;
 	}
 
+#ifdef TT_MEMUTIL
+if (use_nontemporal_copy)
+{
 	while (w >= 4 && ((unsigned long)d & 15))
 	{
-	    *(uint32_t *)d = *(uint32_t *)s;
+	    save_32_write_combining ((int*)d, *(int*)s);
 
 	    w -= 4;
 	    s += 4;
 	    d += 4;
 	}
 
 	while (w >= 64)
 	{
 	    __m128i xmm0, xmm1, xmm2, xmm3;
 
+	    _mm_prefetch((char const *)s + (200*64/34+192), _MM_HINT_NTA);
+
 	    xmm0 = load_128_unaligned ((__m128i*)(s));
 	    xmm1 = load_128_unaligned ((__m128i*)(s + 16));
 	    xmm2 = load_128_unaligned ((__m128i*)(s + 32));
 	    xmm3 = load_128_unaligned ((__m128i*)(s + 48));
 
+	    save_128_write_combining ((__m128i*)(d),    xmm0);
+	    save_128_write_combining ((__m128i*)(d + 16), xmm1);
+	    save_128_write_combining ((__m128i*)(d + 32), xmm2);
+	    save_128_write_combining ((__m128i*)(d + 48), xmm3);
+
+	    s += 64;
+	    d += 64;
+	    w -= 64;
+	}
+
+	while (w >= 16)
+	{
+	    save_128_write_combining ((__m128i*)d, load_128_unaligned ((__m128i*)s) );
+
+	    w -= 16;
+	    d += 16;
+	    s += 16;
+	}
+
+	while (w >= 4)
+	{
+	    save_32_write_combining ((int*)d, *(int*)s);
+
+	    w -= 4;
+	    s += 4;
+	    d += 4;
+	}
+}
+else
+#endif
+{
+	while (w >= 4 && ((unsigned long)d & 15))
+	{
+	    *(uint32_t *)d = *(uint32_t *)s;
+
+	    w -= 4;
+	    s += 4;
+	    d += 4;
+	}
+
+	while (w >= 64)
+	{
+	    __m128i xmm0, xmm1, xmm2, xmm3;
+
+	    xmm0 = load_128_unaligned ((__m128i*)(s));
+	    xmm1 = load_128_unaligned ((__m128i*)(s + 16));
+	    xmm2 = load_128_unaligned ((__m128i*)(s + 32));
+	    xmm3 = load_128_unaligned ((__m128i*)(s + 48));
+
 	    save_128_aligned ((__m128i*)(d),    xmm0);
 	    save_128_aligned ((__m128i*)(d + 16), xmm1);
 	    save_128_aligned ((__m128i*)(d + 32), xmm2);
 	    save_128_aligned ((__m128i*)(d + 48), xmm3);
 
 	    s += 64;
 	    d += 64;
 	    w -= 64;
@@ -4548,26 +4701,33 @@ pixman_blt_sse2 (uint32_t *src_bits,
 	while (w >= 4)
 	{
 	    *(uint32_t *)d = *(uint32_t *)s;
 
 	    w -= 4;
 	    s += 4;
 	    d += 4;
 	}
+}
 
 	if (w >= 2)
 	{
 	    *(uint16_t *)d = *(uint16_t *)s;
 	    w -= 2;
 	    s += 2;
 	    d += 2;
 	}
     }
 
+#ifdef TT_MEMUTIL
+    if (use_nontemporal_copy)
+    {
+        _mm_sfence();
+    }
+#endif
 
     return TRUE;
 }
 
 static void
 sse2_composite_copy_area (pixman_implementation_t *imp,
                           pixman_composite_info_t *info)
 {

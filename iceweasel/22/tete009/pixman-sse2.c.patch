diff --git a/gfx/cairo/libpixman/src/pixman-sse2.c b/gfx/cairo/libpixman/src/pixman-sse2.c
--- a/gfx/cairo/libpixman/src/pixman-sse2.c
+++ b/gfx/cairo/libpixman/src/pixman-sse2.c
@@ -375,16 +375,23 @@ load_128_unaligned (const __m128i* src)
  */
 static force_inline void
 save_128_write_combining (__m128i* dst,
                           __m128i  data)
 {
     _mm_stream_si128 (dst, data);
 }
 
+/* save 1 pixels using Write Combining memory */
+static force_inline void
+save_32_write_combining (int* dst, int data)
+{
+    _mm_stream_si32 (dst, data);
+}
+
 /* save 4 pixels on a 16-byte boundary aligned address */
 static force_inline void
 save_128_aligned (__m128i* dst,
                   __m128i  data)
 {
     _mm_store_si128 (dst, data);
 }
 
@@ -4677,16 +4684,20 @@ sse2_composite_add_n_8_8888 (pixman_impl
 		      unpack_32_1x128 (*dst)));
 	    }
 	    dst++;
 	    w--;
 	}
     }
 }
 
+#ifdef TT_MEMUTIL
+extern uint32_t dwNonTemporalMemcpySizeMin;
+#endif
+
 static pixman_bool_t
 sse2_blt (pixman_implementation_t *imp,
           uint32_t *               src_bits,
           uint32_t *               dst_bits,
           int                      src_stride,
           int                      dst_stride,
           int                      src_bpp,
           int                      dst_bpp,
@@ -4695,16 +4706,19 @@ sse2_blt (pixman_implementation_t *imp,
           int                      dest_x,
           int                      dest_y,
           int                      width,
           int                      height)
 {
     uint8_t *   src_bytes;
     uint8_t *   dst_bytes;
     int byte_width;
+#ifdef TT_MEMUTIL
+    pixman_bool_t use_nontemporal_copy;
+#endif
 
     if (src_bpp != dst_bpp)
 	return FALSE;
 
     if (src_bpp == 16)
     {
 	src_stride = src_stride * (int) sizeof (uint32_t) / 2;
 	dst_stride = dst_stride * (int) sizeof (uint32_t) / 2;
@@ -4724,16 +4738,20 @@ sse2_blt (pixman_implementation_t *imp,
 	src_stride *= 4;
 	dst_stride *= 4;
     }
     else
     {
 	return FALSE;
     }
 
+#ifdef TT_MEMUTIL
+    use_nontemporal_copy = ((uint32_t)(byte_width * height) > dwNonTemporalMemcpySizeMin);
+#endif
+
     while (height--)
     {
 	int w;
 	uint8_t *s = src_bytes;
 	uint8_t *d = dst_bytes;
 	src_bytes += src_stride;
 	dst_bytes += dst_stride;
 	w = byte_width;
@@ -4741,34 +4759,88 @@ sse2_blt (pixman_implementation_t *imp,
 	while (w >= 2 && ((uintptr_t)d & 3))
 	{
 	    *(uint16_t *)d = *(uint16_t *)s;
 	    w -= 2;
 	    s += 2;
 	    d += 2;
 	}
 
+#ifdef TT_MEMUTIL
+if (use_nontemporal_copy)
+{
 	while (w >= 4 && ((uintptr_t)d & 15))
 	{
-	    *(uint32_t *)d = *(uint32_t *)s;
+	    save_32_write_combining ((int*)d, *(int*)s);
 
 	    w -= 4;
 	    s += 4;
 	    d += 4;
 	}
 
 	while (w >= 64)
 	{
 	    __m128i xmm0, xmm1, xmm2, xmm3;
 
+	    _mm_prefetch((char const *)s + (200*64/34+192), _MM_HINT_NTA);
+
 	    xmm0 = load_128_unaligned ((__m128i*)(s));
 	    xmm1 = load_128_unaligned ((__m128i*)(s + 16));
 	    xmm2 = load_128_unaligned ((__m128i*)(s + 32));
 	    xmm3 = load_128_unaligned ((__m128i*)(s + 48));
 
+	    save_128_write_combining ((__m128i*)(d),    xmm0);
+	    save_128_write_combining ((__m128i*)(d + 16), xmm1);
+	    save_128_write_combining ((__m128i*)(d + 32), xmm2);
+	    save_128_write_combining ((__m128i*)(d + 48), xmm3);
+
+	    s += 64;
+	    d += 64;
+	    w -= 64;
+	}
+
+	while (w >= 16)
+	{
+	    save_128_write_combining ((__m128i*)d, load_128_unaligned ((__m128i*)s) );
+
+	    w -= 16;
+	    d += 16;
+	    s += 16;
+	}
+
+	while (w >= 4)
+	{
+	    save_32_write_combining ((int*)d, *(int*)s);
+
+	    w -= 4;
+	    s += 4;
+	    d += 4;
+	}
+}
+else
+#endif
+{
+	while (w >= 4 && ((uintptr_t)d & 15))
+	{
+	    *(uint32_t *)d = *(uint32_t *)s;
+
+	    w -= 4;
+	    s += 4;
+	    d += 4;
+	}
+
+	while (w >= 64)
+	{
+	    __m128i xmm0, xmm1, xmm2, xmm3;
+
+	    xmm0 = load_128_unaligned ((__m128i*)(s));
+	    xmm1 = load_128_unaligned ((__m128i*)(s + 16));
+	    xmm2 = load_128_unaligned ((__m128i*)(s + 32));
+	    xmm3 = load_128_unaligned ((__m128i*)(s + 48));
+
 	    save_128_aligned ((__m128i*)(d),    xmm0);
 	    save_128_aligned ((__m128i*)(d + 16), xmm1);
 	    save_128_aligned ((__m128i*)(d + 32), xmm2);
 	    save_128_aligned ((__m128i*)(d + 48), xmm3);
 
 	    s += 64;
 	    d += 64;
 	    w -= 64;
@@ -4786,26 +4858,34 @@ sse2_blt (pixman_implementation_t *imp,
 	while (w >= 4)
 	{
 	    *(uint32_t *)d = *(uint32_t *)s;
 
 	    w -= 4;
 	    s += 4;
 	    d += 4;
 	}
+}
 
 	if (w >= 2)
 	{
 	    *(uint16_t *)d = *(uint16_t *)s;
 	    w -= 2;
 	    s += 2;
 	    d += 2;
 	}
     }
 
+#ifdef TT_MEMUTIL
+    if (use_nontemporal_copy)
+    {
+        _mm_sfence();
+    }
+#endif
+
     return TRUE;
 }
 
 static void
 sse2_composite_copy_area (pixman_implementation_t *imp,
                           pixman_composite_info_t *info)
 {
     PIXMAN_COMPOSITE_ARGS (info);
